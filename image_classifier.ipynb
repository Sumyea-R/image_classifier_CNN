{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classifier\n",
    "\n",
    "Before diving into model building, the dataset needs to be prepared for training, validation, and testing. <br />\n",
    "First the Data Directory is split into train(90%) and test(10%) directories. <br />\n",
    "Furthermore the training dataset is divided into train(80%) and validation(20%) set. <br />\n",
    "\n",
    "The model itself is a CNN, as this is an image classification task. The first two layers of the model is dedicated for image preprocessing. <br />\n",
    "Where augmentation (zoom, rotation, flip) is done to avoid overfitting and normalisation is done to standardise the images.<br />\n",
    "Rest of the model follows standard image classification procedure, having three convolution layer and maxpool layers in between. <br />\n",
    "To avoid further overfitting dropout is added. <br />\n",
    "\n",
    "Another approach for building an image classifier is to use an already pretrained model. <br /> \n",
    "Using a pre-trained model like VGG16 or ResNet50 helps leverage the features learned from large-scale datasets like ImageNet.\n",
    "\n",
    "I have implemented both approach to compare them and select the best one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Data Directory Into Train and Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "data_path = 'Dataset' #change the directory name as needed\n",
    "class_labels = ['Capacitor', 'IC', 'Resistor']\n",
    "\n",
    "# path to destination folders\n",
    "train_folder = os.path.join(data_path, 'train')\n",
    "test_folder = os.path.join(data_path, 'test')\n",
    "\n",
    "for label in class_labels:\n",
    "\n",
    "    # Create a list of image filenames in 'data_path'\n",
    "    imgs_list = [filename for filename in os.listdir(data_path + '/' + label) if os.path.splitext(filename)[-1] in ['.jpeg']]\n",
    "\n",
    "    # Sets the random seed \n",
    "    random.seed(42)\n",
    "\n",
    "    # Shuffle the list of image filenames\n",
    "    random.shuffle(imgs_list)\n",
    "\n",
    "    # determine the number of images for each set\n",
    "    train_size = int(len(imgs_list) * 0.9)\n",
    "    test_size = int(len(imgs_list) * 0.1)\n",
    "\n",
    "    for folder_path in [train_folder + '/' + label, test_folder + '/' + label]:\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    # Copy image files to destination folders\n",
    "    for i, f in enumerate(imgs_list):\n",
    "        if i < train_size:\n",
    "            dest_folder = train_folder + '/' + label\n",
    "        else:\n",
    "            dest_folder = test_folder + '/' + label\n",
    "        shutil.copy(os.path.join(data_path + '/' + label, f), os.path.join(dest_folder, f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "test_dir = data_path + '/test'\n",
    "test_dir = pathlib.Path(test_dir).with_suffix('')\n",
    "\n",
    "train_dir = data_path + '/train'\n",
    "train_dir = pathlib.Path(train_dir).with_suffix('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, Validation and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1845 files belonging to 3 classes.\n",
      "Using 1476 files for training.\n",
      "Found 1845 files belonging to 3 classes.\n",
      "Using 369 files for validation.\n",
      "Found 216 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "img_height = 640\n",
    "img_width = 640\n",
    "\n",
    "#train, validation and test set\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"training\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"validation\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=32)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=123,\n",
    "    image_size=(640, 640),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "To avoid overfitting random transformations(Flip, Rotation, Zoom) are done. This data augmentation layer will be added to the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumyea/Desktop/Job_Application/Evo/env/lib/python3.12/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Model\n",
    "\n",
    "The sequencial keras model consists of three 2D convolution layers, having a maxpool layer between each convolution layer. \n",
    "\n",
    "The images are normalized with a rescaling layer that standardizes the RGB channel values from [0, 255] to [0, 1]. \n",
    "\n",
    "A dropout layer is added to avoid overfitting followed by the fully connected layer with 128 units. \n",
    "\n",
    "ReLU activation function is used to activate the layers, but the output layer is activated with softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile The Model\n",
    "\n",
    "As a good starting point adam optimizer and ctegorical cross entropy loss function is used to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train The Model\n",
    "\n",
    "Train the created model monitoring the validation loss for early stopping and save the best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 11s/step - accuracy: 0.6902 - loss: 7.6161 - val_accuracy: 0.8537 - val_loss: 0.4343\n",
      "Epoch 2/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 10s/step - accuracy: 0.7858 - loss: 0.6591 - val_accuracy: 0.8916 - val_loss: 0.3038\n",
      "Epoch 3/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 13s/step - accuracy: 0.8597 - loss: 0.4034 - val_accuracy: 0.8943 - val_loss: 0.3105\n",
      "Epoch 4/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 13s/step - accuracy: 0.8933 - loss: 0.3065 - val_accuracy: 0.8889 - val_loss: 0.3163\n",
      "Epoch 5/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 11s/step - accuracy: 0.8958 - loss: 0.3089 - val_accuracy: 0.9079 - val_loss: 0.2795\n",
      "Epoch 6/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 10s/step - accuracy: 0.8572 - loss: 0.4201 - val_accuracy: 0.9214 - val_loss: 0.2535\n",
      "Epoch 7/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 10s/step - accuracy: 0.8867 - loss: 0.3014 - val_accuracy: 0.8943 - val_loss: 0.3111\n",
      "Epoch 8/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 10s/step - accuracy: 0.8868 - loss: 0.3065 - val_accuracy: 0.9133 - val_loss: 0.2643\n",
      "Epoch 9/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 10s/step - accuracy: 0.9040 - loss: 0.2339 - val_accuracy: 0.9295 - val_loss: 0.2222\n",
      "Epoch 10/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 9s/step - accuracy: 0.9138 - loss: 0.2366 - val_accuracy: 0.9079 - val_loss: 0.2795\n",
      "Epoch 11/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 10s/step - accuracy: 0.9129 - loss: 0.2273 - val_accuracy: 0.9322 - val_loss: 0.2790\n",
      "Epoch 12/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 10s/step - accuracy: 0.9159 - loss: 0.2393 - val_accuracy: 0.9322 - val_loss: 0.3053\n",
      "Epoch 13/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 9s/step - accuracy: 0.9076 - loss: 0.2377 - val_accuracy: 0.9241 - val_loss: 0.2481\n",
      "Epoch 14/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 9s/step - accuracy: 0.9212 - loss: 0.2265 - val_accuracy: 0.9295 - val_loss: 0.3011\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "epochs = 25\n",
    "# Define the callbacks\n",
    "model_path = 'models/'\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_checkpoint = ModelCheckpoint(model_path+'best_model.keras',monitor='val_loss', \n",
    "                                   verbose=0, save_best_only=True,save_weights_only=False, mode='auto')\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  callbacks=[early_stopping, model_checkpoint],\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumyea/Desktop/Job_Application/Evo/myenv/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.3140\n",
      "[test loss, test accuracy]: [0.30860400199890137, 0.9120370149612427]\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(model_path+ 'best_model.keras')\n",
    "eval_result = new_model.evaluate(test_ds)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Model\n",
    "\n",
    "We can see we have achieved 91% accuracy with the trained model. To check if further accuracy can be achieved lets use an already trained model.\n",
    "\n",
    "VGG16 is used as the base model, followed by an average pooling layer, a fully connected layer and a dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(640, 640, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile The Model\n",
    "\n",
    "Adam optimizer and ctegorical cross entropy loss function is used to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train The Model\n",
    "\n",
    "Train the created model monitoring the validation loss for early stopping and save the best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2679s\u001b[0m 57s/step - accuracy: 0.7145 - loss: 1.8726 - val_accuracy: 0.9485 - val_loss: 0.1743\n",
      "Epoch 2/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2816s\u001b[0m 60s/step - accuracy: 0.9297 - loss: 0.2306 - val_accuracy: 0.9593 - val_loss: 0.1069\n",
      "Epoch 3/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2497s\u001b[0m 53s/step - accuracy: 0.9541 - loss: 0.1271 - val_accuracy: 0.9675 - val_loss: 0.0872\n",
      "Epoch 4/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2563s\u001b[0m 55s/step - accuracy: 0.9658 - loss: 0.1032 - val_accuracy: 0.9756 - val_loss: 0.0716\n",
      "Epoch 5/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2505s\u001b[0m 53s/step - accuracy: 0.9740 - loss: 0.0763 - val_accuracy: 0.9783 - val_loss: 0.0714\n",
      "Epoch 6/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2543s\u001b[0m 54s/step - accuracy: 0.9796 - loss: 0.0638 - val_accuracy: 0.9810 - val_loss: 0.0648\n",
      "Epoch 7/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2883s\u001b[0m 62s/step - accuracy: 0.9821 - loss: 0.0544 - val_accuracy: 0.9810 - val_loss: 0.0582\n",
      "Epoch 8/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2969s\u001b[0m 63s/step - accuracy: 0.9898 - loss: 0.0416 - val_accuracy: 0.9810 - val_loss: 0.0581\n",
      "Epoch 9/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7818s\u001b[0m 169s/step - accuracy: 0.9863 - loss: 0.0505 - val_accuracy: 0.9810 - val_loss: 0.0579\n",
      "Epoch 10/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8511s\u001b[0m 180s/step - accuracy: 0.9889 - loss: 0.0389 - val_accuracy: 0.9864 - val_loss: 0.0498\n",
      "Epoch 11/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5204s\u001b[0m 110s/step - accuracy: 0.9871 - loss: 0.0384 - val_accuracy: 0.9864 - val_loss: 0.0476\n",
      "Epoch 12/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2532s\u001b[0m 54s/step - accuracy: 0.9912 - loss: 0.0261 - val_accuracy: 0.9810 - val_loss: 0.0544\n",
      "Epoch 13/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2598s\u001b[0m 55s/step - accuracy: 0.9923 - loss: 0.0319 - val_accuracy: 0.9892 - val_loss: 0.0464\n",
      "Epoch 14/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2651s\u001b[0m 57s/step - accuracy: 0.9908 - loss: 0.0326 - val_accuracy: 0.9864 - val_loss: 0.0492\n",
      "Epoch 15/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2617s\u001b[0m 56s/step - accuracy: 0.9945 - loss: 0.0213 - val_accuracy: 0.9892 - val_loss: 0.0382\n",
      "Epoch 16/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2582s\u001b[0m 55s/step - accuracy: 0.9899 - loss: 0.0295 - val_accuracy: 0.9864 - val_loss: 0.0446\n",
      "Epoch 17/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2936s\u001b[0m 63s/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9837 - val_loss: 0.0480\n",
      "Epoch 18/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3029s\u001b[0m 65s/step - accuracy: 0.9955 - loss: 0.0157 - val_accuracy: 0.9919 - val_loss: 0.0394\n",
      "Epoch 19/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3261s\u001b[0m 70s/step - accuracy: 0.9933 - loss: 0.0234 - val_accuracy: 0.9864 - val_loss: 0.0413\n",
      "Epoch 20/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3026s\u001b[0m 65s/step - accuracy: 0.9976 - loss: 0.0141 - val_accuracy: 0.9864 - val_loss: 0.0441\n",
      "Epoch 21/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3140s\u001b[0m 67s/step - accuracy: 0.9941 - loss: 0.0207 - val_accuracy: 0.9864 - val_loss: 0.0380\n",
      "Epoch 22/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3013s\u001b[0m 64s/step - accuracy: 0.9951 - loss: 0.0141 - val_accuracy: 0.9892 - val_loss: 0.0349\n",
      "Epoch 23/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3312s\u001b[0m 71s/step - accuracy: 0.9922 - loss: 0.0180 - val_accuracy: 0.9864 - val_loss: 0.0389\n",
      "Epoch 24/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2968s\u001b[0m 63s/step - accuracy: 0.9945 - loss: 0.0205 - val_accuracy: 0.9864 - val_loss: 0.0364\n",
      "Epoch 25/25\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3083s\u001b[0m 66s/step - accuracy: 0.9939 - loss: 0.0179 - val_accuracy: 0.9837 - val_loss: 0.0444\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "epochs = 25\n",
    "# Define the callbacks\n",
    "model_path = 'models/'\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_checkpoint = ModelCheckpoint(model_path+'best_model_pretrained.keras',monitor='val_loss', \n",
    "                                   verbose=0, save_best_only=True,save_weights_only=False, mode='auto')\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  callbacks=[early_stopping, model_checkpoint],\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumyea/Desktop/Job_Application/Evo/myenv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 41s/step - accuracy: 0.9906 - loss: 0.0485\n",
      "[test loss, test accuracy]: [0.10612954944372177, 0.9814814925193787]\n"
     ]
    }
   ],
   "source": [
    "model.save(model_path+ 'best_model_pretrained.keras')\n",
    "new_model = tf.keras.models.load_model(model_path+ 'best_model_pretrained.keras')\n",
    "eval_result = model.evaluate(test_ds)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident the pretrained model performs better with 98% accuracy, this model will be deployed for the web app. <br />\n",
    "As with the pretrained model I have already achieved a good accuracy, no further fine tuning is done. <br />\n",
    "Although both models are included in the submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
